{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning parameters and cross validation\n",
    "\n",
    "This notebook illustrates the \"master algorithm\". How to make\n",
    "optimal use of your data, apply preprocessing steps, tune\n",
    "hyper-parameters and get an estimate of your algorithm on\n",
    "future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, validation and test\n",
    "\n",
    "Using the breast cancer dataset once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full pipeline\n",
    "\n",
    "This is a full example of how you would pick the best value for `n_neighbors`, make optimal use of your dataset, and obtain a prediction for your generalisation error.\n",
    "\n",
    "It looks simple and straightforward. It is. However the most frequent source of mistakes in real world problems is \"information leakage\" of some form or another. When this happens the performance estimates become biased and essentially useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "# features are on very different scales so let's\n",
    "# scale them all.\n",
    "X = scale(X)\n",
    "\n",
    "neighbors = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=2)\n",
    "\n",
    "cross_val_scores = []\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    # this function performs a loop of splitting the data,\n",
    "    # fitting one split, evaluating on the others\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "\n",
    "print(\"best cross-validation score: {:.3f}\".format(np.max(cross_val_scores)))\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "\n",
    "print(\"best n_neighbors: {}\".format(best_n_neighbors))\n",
    "\n",
    "# fit on the whole training dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"test-set score: {:.3f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and pipelines\n",
    "\n",
    "Any preprocessing steps you want to perform need to be performed inside the cross-validation loop. Checkout scikit-learn's `Pipeline` to make this nice and easy to use.\n",
    "\n",
    "### Question\n",
    "What mistake did we make at the beginning of this notebook?\n",
    "```\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# features are on very different scales so let's\n",
    "# scale them all.\n",
    "X = scale(X)\n",
    "```\n",
    "\n",
    "Use `make_pipeline` to create a new estimator that scales the data\n",
    "and fits a `KNeighborsClassifier` to the data. Find the best setting\n",
    "for `n_neighbors`, and obtain an estimate of the accuracy on unseen\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "neighbors = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=2)\n",
    "\n",
    "cross_val_scores = []\n",
    "for i in neighbors:\n",
    "    pipeline = make_pipeline(StandardScaler(),\n",
    "                             KNeighborsClassifier(n_neighbors=i)\n",
    "                            )\n",
    "    # this function performs a loop of splitting the data,\n",
    "    # fitting one split, evaluating on the others\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=10)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "\n",
    "print(\"best cross-validation score: {:.3f}\".format(np.max(cross_val_scores)))\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "\n",
    "print(\"best n_neighbors: {}\".format(best_n_neighbors))\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(),\n",
    "                         KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "                        )\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"test-set score: {:.3f}\".format(pipeline.score(X_test, y_test)))\n",
    "                         \n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing is that your preprocessing steps, just like your final algorithm must nto see any data \"from the future\". When you compute the constants by which to scale the data you must not look at the samples in the testing data as that simulates the future.\n",
    "\n",
    "This does mean you need to think about how to handle samples very far away from what you saw in training, or if you are applying other kinds of transforms how to handle values you have never seen, etc. The effect of this is precisely what you want to test and evaluate when you \"simulate the future\" by splitting your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter optimisation\n",
    "\n",
    "You can see there are more and more hyper-parameters cropping up. These are parameters that can not be directly learnt from the data. The only way to know what to set them to is a mixture of prior experience of what ranges of values \"work well\" and then trying those values.\n",
    "\n",
    "Not optimising your hyper-parameters is a fundamental mistake. It can make a huge difference to the performance of your model and especially when you are comparing different types of models (say ensembles of decisions trees to neural networks) you need to optimise the architecture of both! Otherwise you might as well flip a coin in order ot determine which algorithm is better.\n",
    "\n",
    "The above `for`-loop works for one parameter but what if we wanted to tune two parameters?\n",
    "We would end up having to loop over both parameters with two `for`-loops. For three we would have to write three loops, etc. This is such a common task that scikit-learn has some builtin tools for this.\n",
    "\n",
    "In scikit-learn there is `GridSearchCV` and `RandomizedSearchCV`. They themselves follow the `Estimator` API. When you call `fit()` they perform the \"master algorithm\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(),\n",
    "                         KNeighborsClassifier()\n",
    "                         )\n",
    "\n",
    "# parameters for each step in a pipeline\n",
    "# are prefixed with the name of the step\n",
    "# which `make_pipeline` derives from the \n",
    "# class name.\n",
    "# Find out from the documentation how to\n",
    "# specify all odd values between one and 15\n",
    "# as values to try for n_neighbors\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# GridSearchCV will also re-fit your estimator\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=10, n_jobs=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Replace `GridSearchCV` with `RandomizedSearchCV` in the above setup.\n",
    "\n",
    "When or why does it make sense to prefer random search over grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might need to install scipy if you haven't already\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Because the score on the validation set is a random variable it will fluctuate low and high as we try different classification techniques. This means if you try enough different techniques you will end up picking one which \"gets lucky\" on the dataset you use to measure performance.\n",
    "\n",
    "This means that the performance on the validation set is not an unbiased estimate of the generalisation error. Instead we need to have yet another data set that we did not look at during the optimisation process and use that to estimate the performance on future data.\n",
    "\n",
    "Great visual guide to parameter tuning and the bias-variance trade-off:\n",
    "\n",
    "http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Bias-Variance trade-off\n",
    "\n",
    "It can be shown that the best method for making a prediction $\\hat y$ at $x$ is to predict the average of all training examples for which $X = x$. When \"best\" is defined by the average squared error. In practice there is at most one training point at each $x$. In practice this means we settle for:\n",
    "$$\n",
    "\\hat f(x) = \\mathrm{Ave}\\left(y_i \\mid x_i \\in N_k(x)\\right)\n",
    "$$\n",
    "where $N_k(x)$ is the neighbourhood containing $k$ points from $\\mathcal{T}$ nearest to $x$. This is exactly what kNN does. So why not use it always and for everything?\n",
    "\n",
    "The curse of dimensionality: as the number of dimensions increases you need an exponentially larger number of training samples to keep $k$ constant.\n",
    "\n",
    "By making assumptions about the (local) shape of the function we are trying to model we can counteract this and get more stable predictions.\n",
    "\n",
    "Lienar regression assumes that $f(x)$ is well approximated by a globally linear function.\n",
    "\n",
    "In contrast kNN assumes that $f(x)$ is well approximated by a locally constant function.\n",
    "\n",
    "The latter is more flexible, but you have to pay a price for this flexibility. If you do not need the flexibility you can obtain a more stable estimate by making more assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def non_linear_f(x):\n",
    "    return np.exp(-x ** 2) + 1.5 * np.exp(-(x - 2) ** 2)\n",
    "\n",
    "\n",
    "def linear_f(x, beta0=2.19, beta1=3.141):\n",
    "    rng = np.random.RandomState()\n",
    "    return beta0 + beta1 * x + rng.randn(x.shape[0]) * 2.\n",
    "\n",
    "\n",
    "def make_linear_data():\n",
    "    x = np.linspace(-2, 2, 1000)\n",
    "    rng = np.random.RandomState()\n",
    "    rng.shuffle(x)\n",
    "    X = np.sort(x[:40])\n",
    "    y = linear_f(X)\n",
    "\n",
    "    X = X.reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def make_nonlinear_data():\n",
    "    x = np.linspace(-2, 2, 1000)\n",
    "    rng = np.random.RandomState()\n",
    "    rng.shuffle(x)\n",
    "    X = np.sort(x[:40])\n",
    "    y = non_linear_f(X)\n",
    "\n",
    "    X = X.reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# show a noisy but linear data set, compare variance of kNN with linear regression\n",
    "line = np.linspace(-2, 2, 100).reshape(-1, 1)\n",
    "\n",
    "for n in range(20):\n",
    "    X, y = make_linear_data()\n",
    "    rgr = LinearRegression()\n",
    "    rgr.fit(X, y)\n",
    "    plt.plot(line, rgr.predict(line), '-r', alpha=0.2, label='linear model', lw=3)\n",
    "    \n",
    "    rgr = KNeighborsRegressor(n_neighbors=3)\n",
    "    rgr.fit(X, y)\n",
    "    plt.plot(line, rgr.predict(line), '-b', alpha=0.2, label='kNN', lw=3)\n",
    "    #break\n",
    "\n",
    "plt.plot(X, y, 'o', label='true f(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel(\"f(x)\");\n",
    "#plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a **non linear** data set, compare bias of kNN with linear regression\n",
    "plt.plot(line, non_linear_f(line), 'k-', lw=3, label='true f(x)')\n",
    "linear = []\n",
    "knn = []\n",
    "for n in range(20):\n",
    "    X, y = make_nonlinear_data()\n",
    "    rgr = LinearRegression()\n",
    "    rgr.fit(X, y)\n",
    "    linear.append(rgr.predict(line))\n",
    "    \n",
    "    rgr = KNeighborsRegressor(n_neighbors=3)\n",
    "    rgr.fit(X, y)\n",
    "    knn.append(rgr.predict(line))\n",
    "\n",
    "plt.plot(line, np.array(linear).mean(axis=0), '-b', lw=2, label='Average linear model')\n",
    "plt.plot(line, np.array(knn).mean(axis=0), '-r', lw=2, label='Average kNN model');\n",
    "plt.legend(loc='best');\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('f(x)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
