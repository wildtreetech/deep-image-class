{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "In this section we will implement a linear regression model trainable with SGD using numpy. Here are the objectives:\n",
    "\n",
    "1. Implement a simple forward model: $y = W x + b$\n",
    "\n",
    "1. build a `predict` function which returns the predicted regression value given an input $x$\n",
    "\n",
    "1. build an `accuracy` function for a batch of inputs $X$ and the corresponding expected outputs $y_{true}$ (for regression we typically use Mean Squared Error (MSE) as metric)\n",
    "\n",
    "1. build a `grad` function which computes the gradients for an $x$ and its corresponding expected output $y_{true}$ ; check that the gradients are well defined\n",
    "\n",
    "1. build a `train` function which uses the `grad` function output to update $W$ and $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our toy data for this task\n",
    "# experiment with the number of points, more\n",
    "# points should be easier for debugging as\n",
    "# statistical noise will be smaller\n",
    "X = np.random.uniform(0, 10, size=20*10)\n",
    "temp = 1.3*X + 15 + np.random.normal(0, 1, size=20*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data, on the x axis\n",
    "# the minutes of sunshine and on\n",
    "# the y-axis the temperature\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the big `LinearRegression` class. Once you fill in all the gaps it will let you perform linear regression and we will keep building on this class' structure during the day. Maybe a class structure like this is overkill for linear regression, but we can use the same structure for our simple neural network later.\n",
    "\n",
    "We will perform linear regression and find the coefficients `W` and `b` by gradient descent. This is not how you would solve this in reality, but stick with it for the moment so we can create the basis for Logistic Regression later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self):\n",
    "        self.W = np.random.uniform(high=0.5, low=-0.5)\n",
    "        self.b = np.random.uniform(high=0.5, low=-0.5)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # TODO: for each sample in X return the predicted value, X is a vector!\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def grad_loss(self, x, y_true):\n",
    "        # TODO?: compute gradient with respect to W and b for one sample x\n",
    "        # and the true value y_true\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def train(self, x, y, learning_rate):\n",
    "        # TODO: compute one step of the gradient descent update\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def loss(self, x, y):\n",
    "        # TODO: compute the loss for the sample x with true value y\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        # TODO: compute accuracy for samples X with true values y\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "* how do you know that you trained for enough epochs?\n",
    "* visualise how the loss changes over the epochs\n",
    "* are more epochs always better? How could you show this?\n",
    "* change the setup to use stochastic gradient descent\n",
    "* (bonus) visualise the values of W and b over the epochs\n",
    "* (bonus) can you see a difference for the paths of W and b between mini batch SGD and single sample SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "print('initial value of W: %.4f and b: %.4f' % (lr.W, lr.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.W = 1.3\n",
    "lr.b = 15.\n",
    "\n",
    "line = np.linspace(0, 10, 100)\n",
    "\n",
    "plt.plot(X, temp, 'o')\n",
    "plt.plot(line, lr.predict(line), c='k');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "learning_rate = 0.01\n",
    "\n",
    "# train the model by looping through the\n",
    "# data 100 times. After each sample we\n",
    "# update the weights W and bias b\n",
    "for n in range(100):\n",
    "    for (x_, y_) in zip(X, temp):\n",
    "        lr.train(x_, y_, learning_rate)\n",
    "    train_acc = lr.accuracy(X, temp)\n",
    "\n",
    "plt.plot(X, temp, 'o')\n",
    "plt.plot(line, lr.predict(line), c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the training porcedure to use\n",
    "# stochastic gradient descent. With a\n",
    "# mini batch size of 10\n",
    "\n",
    "lr = LinearRegression()\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "\n",
    "for n in range(100):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "plt.plot(X, temp, 'o')\n",
    "plt.plot(line, lr.predict(line), c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nteract": {
   "version": "0.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
