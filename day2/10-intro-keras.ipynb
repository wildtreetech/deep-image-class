{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training Neural Networks with Keras\n",
    "\n",
    "This notebook is an intrdouction to training a neural network with the high level framework `Keras`. We will use a toy dataset that is about classifying pictures of fashion items.\n",
    "\n",
    "Find out a bit about it from https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles and https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[sample_index],\n",
    "           cmap=plt.cm.gray_r,\n",
    "           interpolation='nearest')\n",
    "plt.title(\"image label: %d\" % y_train[sample_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Normalise all features to be centered on zero with standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = np.asarray(X_train, dtype='float32')\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "y_train = np.asarray(y_train, dtype='int32')\n",
    "\n",
    "X_test = np.asarray(X_test, dtype='float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "y_test = np.asarray(y_test, dtype='int32')\n",
    "\n",
    "# mean = 0 ; standard deviation = 1.0\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# use `scaler` to fit() and transform() both\n",
    "# the training and testing data\n",
    "# Store the transformed data in X_train\n",
    "# and X_test again.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# print(scaler.mean_)\n",
    "# print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display one of the transformed samples (after feature standardization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 45\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[sample_index].reshape(28, 28),\n",
    "           cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"transformed sample\\n(standardization)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaler objects makes it possible to recover the original sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(scaler.inverse_transform(X_train[sample_index]).reshape(28, 28),\n",
    "           cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"original sample\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check we understand the shape of the data\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Feed Forward NN with Keras\n",
    "\n",
    "Objectives of this section:\n",
    "\n",
    "- Build and train your first feedforward network using `Keras`\n",
    "    - https://keras.io/getting-started/functional-api-guide/\n",
    "- Experiment with different optimizers, activations, size of layers, initialisations\n",
    "\n",
    "### The Keras Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a first neural network we need to turn the target variable into a vector \"one-hot-encoding\" representation. Here are the labels of the first samples in the training set encoded as integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides a utility function to convert integer-encoded categorical variables as one-hot encoded values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build and train our first feed forward neural network using the high level API from keras:\n",
    "\n",
    "- first we define the model by stacking operators with the correct dimensions\n",
    "- then we define a loss function and plug in the SGD optimizer\n",
    "- then we feed the model the training data for a fixed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden = 100\n",
    "n_classes = 10\n",
    "\n",
    "inputs = Input(shape=(n_input,))\n",
    "\n",
    "h = Dense(n_hidden)(inputs)\n",
    "h = Activation('tanh')(h)\n",
    "\n",
    "y = Dense(n_classes)(inputs)\n",
    "y = Activation('softmax')(y)\n",
    "\n",
    "model = Model(inputs, y)\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=15, batch_size=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: Impact of the Optimizer\n",
    "\n",
    "- Try to decrease the learning rate value by a factor of 10 or 100. What do you observe?\n",
    "- Try to increase the learning rate value to make the optimization diverge.\n",
    "- (Bonus: Configure the SGD optimizer to enable a Nesterov momentum of 0.9)\n",
    "  \n",
    "Note that the keras API documentation is available at:\n",
    "\n",
    "https://keras.io/\n",
    "\n",
    "It is also possible to learn more about the parameters of a class by using the question mark: type and evaluate:\n",
    "\n",
    "```python\n",
    "optimizers.SGD?\n",
    "```\n",
    "\n",
    "in a jupyter notebook cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace the SGD optimizer by the Adam optimizer from keras and run it\n",
    "  with the default parameters.\n",
    "\n",
    "- Add another hidden layer and use the \"Rectified Linear Unit\" for all\n",
    "  hidden layers. Can you still train the model with Adam with its default global\n",
    "  learning rate?\n",
    "\n",
    "- Bonus: try the Adadelta optimizer (no learning rate to set).\n",
    "\n",
    "Hint: use `optimizers.<TAB>` to tab-complete the list of implemented optimizers in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises: forward pass and generalization\n",
    "\n",
    "Pick any or all of the different models you built above, and:\n",
    "\n",
    "- Compute predictions on the test set using `model.predict(...)`\n",
    "  - what do you get back from `predict()`? How do you conver it back to human readable labels?\n",
    "- Compute the average accuracy of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
