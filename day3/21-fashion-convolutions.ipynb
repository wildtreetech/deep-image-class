{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Fashion\n",
    "\n",
    "This notebook extends your work on classifying fashion items to use image specific operators.\n",
    "\n",
    "How does your deep convolutional neural network do against simple logistic regression?\n",
    "\n",
    "To get some ideas for the structure of your network take a look at the benchmark results here: https://github.com/zalandoresearch/fashion-mnist#benchmark (scroll past the animated GIF). You will find a ranking of algorithms using various convolutional layers and dropout/pooling often with a link to the GitHub repository.\n",
    "\n",
    "This notebook gives you the basic structure. Explore and add to it! For example which samples are misclassified? Is there a category that is harder than others? How small can you make the training data before you lose accuracy? How complex can you make your model? What is your baseline model that you are comparing to? What happens if you perturb the images a bit by adding noise (or otherwise perturbing them)?\n",
    "\n",
    "Note: If you try anything moderately complex in terms of model get yourself setup on http://colab.research.google.com/ to take advantage of their GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, -1)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of filters\n",
    "filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "# create complete model\n",
    "mnist_model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the parameters are in the fully connected part of the network\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mnist_model.fit(X_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.ylim([0, None])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph it looks like this model hasn't been trained to convergence yet. Increase the number opf epochs slightly to fix that, or change the architecture. Time to explore (and get yourself setup on http://colab.research.google.com/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
